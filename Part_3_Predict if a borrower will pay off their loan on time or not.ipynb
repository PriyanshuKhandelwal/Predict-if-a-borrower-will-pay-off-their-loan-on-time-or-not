{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PART 3: Applying ML Algorithm`\n",
    "--------------------------------------------\n",
    "# Machine learning model that can accurately predict if a borrower will pay \n",
    "\n",
    "\n",
    "# off their loan on time or not?\n",
    "In last two notebooks we cleaned data. Our eventual goal is to generate features from data, which we can feed into Machine Learning algorithm. The algorithm will make predictions whether or not loan will be paid off in time or not, which is contained in `loan_status` column of dataset. We prepared data, we cleaned the data, we removed columns containing data that can result into leakage, columns which have zero variance and columns which had redundant information. We also cleaned columns with formatting issues and converted categorical columns to dummy variable.\n",
    "\n",
    "------------------------------------------------\n",
    "\n",
    "#### class imbalance:\n",
    "We know there is class imbalance as number of `1` in **loan_status** column is 6x more than number of `0`. We need to be aware of that as it may impact prediction. Machine learning models may show high accuracy in such case for training set but they aren't actually learning anything from train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loans = pd.read_csv(\"loans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>10</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>10</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>10</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>156.46</td>\n",
       "      <td>3</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment  emp_length  annual_inc  loan_status  \\\n",
       "0     5000.0     10.65       162.87          10     24000.0            1   \n",
       "1     2500.0     15.27        59.83           0     30000.0            0   \n",
       "2     2400.0     15.96        84.33          10     12252.0            1   \n",
       "3    10000.0     13.49       339.31          10     49200.0            1   \n",
       "4     5000.0      7.90       156.46           3     36000.0            1   \n",
       "\n",
       "     dti  delinq_2yrs  inq_last_6mths  open_acc       ...         \\\n",
       "0  27.65          0.0             1.0       3.0       ...          \n",
       "1   1.00          0.0             5.0       3.0       ...          \n",
       "2   8.72          0.0             2.0       2.0       ...          \n",
       "3  20.00          0.0             1.0      10.0       ...          \n",
       "4  11.20          0.0             3.0       9.0       ...          \n",
       "\n",
       "   purpose_major_purchase  purpose_medical  purpose_moving  purpose_other  \\\n",
       "0                       0                0               0              0   \n",
       "1                       0                0               0              0   \n",
       "2                       0                0               0              0   \n",
       "3                       0                0               0              1   \n",
       "4                       0                0               0              0   \n",
       "\n",
       "   purpose_renewable_energy  purpose_small_business  purpose_vacation  \\\n",
       "0                         0                       0                 0   \n",
       "1                         0                       0                 0   \n",
       "2                         0                       1                 0   \n",
       "3                         0                       0                 0   \n",
       "4                         0                       0                 0   \n",
       "\n",
       "   purpose_wedding  term_ 36 months  term_ 60 months  \n",
       "0                0                1                0  \n",
       "1                0                0                1  \n",
       "2                0                1                0  \n",
       "3                0                1                0  \n",
       "4                1                1                0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_rate                              -0.210814\n",
       "term_ 60 months                       -0.171194\n",
       "revol_util                            -0.099547\n",
       "purpose_small_business                -0.078515\n",
       "inq_last_6mths                        -0.070536\n",
       "loan_amnt                             -0.062140\n",
       "pub_rec                               -0.050193\n",
       "dti                                   -0.042815\n",
       "verification_status_Verified          -0.041976\n",
       "installment                           -0.030309\n",
       "purpose_debt_consolidation            -0.021098\n",
       "home_ownership_RENT                   -0.020678\n",
       "delinq_2yrs                           -0.019279\n",
       "emp_length                            -0.016195\n",
       "purpose_other                         -0.015565\n",
       "revol_bal                             -0.007141\n",
       "purpose_renewable_energy              -0.006921\n",
       "home_ownership_OTHER                  -0.006418\n",
       "purpose_house                         -0.006330\n",
       "purpose_educational                   -0.006167\n",
       "verification_status_Source Verified   -0.005351\n",
       "purpose_medical                       -0.003660\n",
       "purpose_moving                        -0.003182\n",
       "home_ownership_OWN                    -0.000475\n",
       "purpose_vacation                      -0.000176\n",
       "home_ownership_NONE                    0.003646\n",
       "open_acc                               0.005667\n",
       "purpose_wedding                        0.019208\n",
       "total_acc                              0.020318\n",
       "purpose_home_improvement               0.021261\n",
       "purpose_car                            0.021491\n",
       "home_ownership_MORTGAGE                0.021635\n",
       "purpose_major_purchase                 0.029175\n",
       "annual_inc                             0.038175\n",
       "purpose_credit_card                    0.043337\n",
       "verification_status_Not Verified       0.044048\n",
       "term_ 36 months                        0.171194\n",
       "loan_status                            1.000000\n",
       "Name: loan_status, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.corr()[\"loan_status\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there is no major correlation between any specific column and target column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Error Metric:\n",
    "Our main focus should be on capturing true positive and true negative. We can adjust with false negative but we should totally **avoid** false positive. As false positive will result in loss of money.\n",
    "\n",
    "For error metric measure, we can't use accuracy, as it may result in loss to us. We need high true positive rate and low false negative rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with False Positive Ratio and False Negative Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# Predict that all loans will be paid off on time,so setting all the values of predictions to 1\n",
    "#predictions = pd.Series(numpy.ones(loans.shape[0]))\n",
    "predictions = pd.Series(numpy.ones(loans.shape[0]))\n",
    "#fpr = fp/fp+tn\n",
    "filter_fp = (predictions==1) & (loans[\"loan_status\"]==0)\n",
    "filter_tn = (predictions==0) & (loans[\"loan_status\"]==0)\n",
    "#tpr = tp/tp+fn\n",
    "filter_tp = (predictions==1) & (loans[\"loan_status\"]==1)\n",
    "filter_fn = (predictions==0) & (loans[\"loan_status\"]==1)\n",
    "\n",
    "fpr = len(loans[filter_fp])/(len(loans[filter_fp])+len(loans[filter_tn]))\n",
    "tpr = len(loans[filter_tp])/(len(loans[filter_tp])+len(loans[filter_fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr,tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that both the rates are 1 and 1. True positive rate is \"1\" implies that we correctly identified good loans. But False Positive rate is \"1\" implies we incorrectly identified bad loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already converted all the columns to Numeric type, so we can easily apply all the machine learning algorithms. Applying machine learning algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "features = loans.drop([\"loan_status\"],axis=1)\n",
    "target = loans[\"loan_status\"]\n",
    "logistic_model.fit(features,target)\n",
    "predictions = logistic_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    37611\n",
       "0       64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model seems overfitting as we are using training set as test set. Let's implement K-Fold cross validation.\n",
    "#### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9987920460880877, 0.9962887363147152)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "features = loans.drop([\"loan_status\"],axis=1)\n",
    "target = loans[\"loan_status\"]\n",
    "logistic_model = LogisticRegression()\n",
    "predictions = cross_val_predict(logistic_model,features,target,cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#True positive rate\n",
    "tp_filter = (loans[\"loan_status\"]==1) & (predictions==1)\n",
    "fn_filter = (loans[\"loan_status\"]==1) & (predictions==0)\n",
    "tpr = len(loans[tp_filter])/(len(loans[tp_filter]) +len(loans[fn_filter]) )\n",
    "\n",
    "#False positive rate\n",
    "fp_filter = (loans[\"loan_status\"]==0) & (predictions==1)\n",
    "tn_filter = (loans[\"loan_status\"]==0) & (predictions==0)\n",
    "fpr = len(loans[fp_filter])/(len(loans[fp_filter]) +len(loans[tn_filter]) )\n",
    "\n",
    "(tpr,fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both *True positive rate* and *False positive rate* are approximately 1, which isn't a good sign. We need to find a way to remove imbalance and ensuring equal participation of both the type of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using parameter: class_weight = balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6644675710834418, 0.3859714232696233)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "features = loans.drop([\"loan_status\"],axis=1)\n",
    "target = loans[\"loan_status\"]\n",
    "#-----------------change is done here\n",
    "logistic_model = LogisticRegression(class_weight=\"balanced\")\n",
    "#----------------------------------------\n",
    "predictions = cross_val_predict(logistic_model,features,target,cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#True positive rate\n",
    "tp_filter = (loans[\"loan_status\"]==1) & (predictions==1)\n",
    "fn_filter = (loans[\"loan_status\"]==1) & (predictions==0)\n",
    "tpr = len(loans[tp_filter])/(len(loans[tp_filter]) +len(loans[fn_filter]) )\n",
    "\n",
    "#False positive rate\n",
    "fp_filter = (loans[\"loan_status\"]==0) & (predictions==1)\n",
    "tn_filter = (loans[\"loan_status\"]==0) & (predictions==0)\n",
    "fpr = len(loans[fp_filter])/(len(loans[fp_filter]) +len(loans[tn_filter]) )\n",
    "\n",
    "(tpr,fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We significantly improved false positive rate in the last screen by **balancing** the classes, which reduced true positive rate. Our true positive rate is now 67% and our false positive rate is around 40%. From conservative inverstor's point of view, its reassuring that the false positive rate is lower because it mean we'll be able to do a better job at avoiding bad loans than if we funded everything. However, we'd only ever decide to fund 67% of the total loans (true positive rate). \n",
    "\n",
    "We can try to lower false positive rate further by assigning harsher penalty for misclassifying negative class. While setting `class_weight` to balanced will automatically set a penalty based on number of `1s` and `0s` in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying penalty manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2514712259183547, 0.09482278715902764)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty = {0:10,1:1}\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "features = loans.drop([\"loan_status\"],axis=1)\n",
    "target = loans[\"loan_status\"]\n",
    "#-----------------change is done here\n",
    "logistic_model = LogisticRegression(class_weight=penalty)\n",
    "#----------------------------------------\n",
    "predictions = cross_val_predict(logistic_model,features,target,cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#True positive rate\n",
    "tp_filter = (loans[\"loan_status\"]==1) & (predictions==1)\n",
    "fn_filter = (loans[\"loan_status\"]==1) & (predictions==0)\n",
    "tpr = len(loans[tp_filter])/(len(loans[tp_filter]) +len(loans[fn_filter]) )\n",
    "\n",
    "#False positive rate\n",
    "fp_filter = (loans[\"loan_status\"]==0) & (predictions==1)\n",
    "tn_filter = (loans[\"loan_status\"]==0) & (predictions==0)\n",
    "fpr = len(loans[fp_filter])/(len(loans[fp_filter]) +len(loans[tn_filter]) )\n",
    "\n",
    "(tpr,fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying manual penalties lowered the false positive rate to 9.5% and hence lowered our risk. Note that this comes at the expense of true positive rate. We we have fewer false positives, we are also missing opportunities to fund more loans and potentially make more money.\n",
    "\n",
    "We can tweak penalties further.But now let's use `Random Forests`.\n",
    "Random Forests are able to work with non linear data and learn complex conditionals.Logistic Regression are only able to work with Linear data.\n",
    "\n",
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9700799107972495, 0.9181666357394693)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "features = loans.drop([\"loan_status\"],axis=1)\n",
    "target = loans[\"loan_status\"]\n",
    "#-----------------change is done here\n",
    "model = RandomForestClassifier(class_weight=\"balanced\",random_state=1)\n",
    "#----------------------------------------\n",
    "predictions = cross_val_predict(model,features,target,cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#True positive rate\n",
    "tp_filter = (loans[\"loan_status\"]==1) & (predictions==1)\n",
    "fn_filter = (loans[\"loan_status\"]==1) & (predictions==0)\n",
    "tpr = len(loans[tp_filter])/(len(loans[tp_filter]) +len(loans[fn_filter]) )\n",
    "\n",
    "#False positive rate\n",
    "fp_filter = (loans[\"loan_status\"]==0) & (predictions==1)\n",
    "tn_filter = (loans[\"loan_status\"]==0) & (predictions==0)\n",
    "fpr = len(loans[fp_filter])/(len(loans[fp_filter]) +len(loans[tn_filter]) )\n",
    "\n",
    "(tpr,fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "Using random forest classifier ddn't improve our false positive rate. The model is likely weighting too heavily on `1` class and still predicting `1s`.We can further apply penalties.\n",
    "\n",
    "Our best model so far had true positive rate of `25%` and false positive rate of `9%`.\n",
    "\n",
    "We can futher tune our models for better predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
